{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import json\n",
    "import codecs\n",
    "import jieba\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "i=1000\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "i=2000\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "i=3000\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def news_vector_dict(file_root, title_scale, doc_scale, min_df):\n",
    "    file = codecs.open(file_root, 'r', 'utf-8')\n",
    "    news_dict = json.load(file)\n",
    "    \n",
    "    # 分词，在词之间加空格，重新组成文章\n",
    "#     stop_file = codecs.open('./data/stop_words.txt', 'r', 'utf-8')\n",
    "#     stop_list = stop_file.read().split('\\n')\n",
    "    i = 0\n",
    "    title_array = []\n",
    "    doc_array = []\n",
    "    for news_key in news_dict:\n",
    "        title_text = news_dict[news_key][0]\n",
    "        doc_text = news_dict[news_key][1]\n",
    "        title = ' '.join(jieba.lcut(title_text))\n",
    "        txt = jieba.lcut(doc_text)\n",
    "        k = len(txt)-1\n",
    "        while k >= 0:\n",
    "            if txt[k].isdigit():\n",
    "                del(txt[k])\n",
    "            k-=1\n",
    "        doc = ' '.join(txt)\n",
    "        title_array.append(title)\n",
    "        doc_array.append(doc)\n",
    "        i += 1\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "    \n",
    "    # tf-idf算法，文章转化为一个归一化的向量\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df = min_df)\n",
    "    doc_matrix = tfidf_vectorizer.fit_transform(doc_array)\n",
    "    title_matrix = tfidf_vectorizer.transform(title_array)\n",
    "    \n",
    "    word_bag = {}\n",
    "    for key in tfidf_vectorizer.vocabulary_:\n",
    "        word_bag.setdefault(tfidf_vectorizer.vocabulary_[key], key)\n",
    "    \n",
    "    # 计算文章加权vector\n",
    "    news_matrix = (title_matrix.todense() * title_scale + doc_matrix.todense() * doc_scale).tolist()\n",
    "    \n",
    "    # 构建news_key : vector字典\n",
    "    i = 0\n",
    "    news_vector_dict = {}\n",
    "    for news_key in news_dict:\n",
    "        news_vector_dict.setdefault(news_key, news_matrix[i])\n",
    "        i += 1\n",
    "        if i % 1000 == 0:\n",
    "            print('i='+str(i))\n",
    "            print(news_matrix[i][:10])\n",
    "            \n",
    "         #打印文章关键词和权重\n",
    "#         if i < 5:\n",
    "#             news_words = []\n",
    "#             news_words_weight = []\n",
    "#             for j in range(len(news_matrix[i])):\n",
    "#                 if news_matrix[i][j] > 0:\n",
    "#                     news_words.append(word_bag[j])\n",
    "#                     news_words_weight.append(news_matrix[i][j])\n",
    "#             print(news_words)\n",
    "#             print(news_words_weight)\n",
    "            \n",
    "                    \n",
    "\n",
    "    \n",
    "    return news_vector_dict\n",
    "\n",
    "file_root = './data/_news_data_clean.json'\n",
    "title_scale = 0.5\n",
    "doc_scale = 1.0 - title_scale\n",
    "min_df = 20\n",
    "_news_vector_dict = news_vector_dict(file_root, title_scale, doc_scale, min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_back(t):\n",
    "    a = int(t-1393603200)\n",
    "    return int(a / 86400)\n",
    "\n",
    "def user_vector_dict(news_vector_dict):\n",
    "    file = codecs.open('./data/_user_data_training_clean.json', 'r', 'utf-8')\n",
    "    news_data = codecs.open('./data/_news_data_clean.json', 'r', 'utf-8')\n",
    "    user_dict = json.load(file)\n",
    "    news_d = json.load(news_data)\n",
    "    \n",
    "    j = 0\n",
    "    user_vector_dict = {}\n",
    "    # 每一个用户\n",
    "    for user_key in user_dict:\n",
    "        # 该用户读过的所有新闻的向量和为用户向量\n",
    "        i = 0\n",
    "        time_scale = 0\n",
    "        vector_sum = numpy.matrix('0.0')\n",
    "        for user_news_key in user_dict[user_key]:\n",
    "            vector = numpy.matrix(news_vector_dict[user_news_key])\n",
    "            time_scale = time_back(news_d[user_news_key][2]) / 5 + 1\n",
    "            vector_sum = vector * 1 + vector_sum\n",
    "            i += 1\n",
    "        if i != 0:\n",
    "            vector_sum /= i\n",
    "        user_vector_dict.setdefault(user_key, vector_sum.tolist()[0])\n",
    "        j += 1\n",
    "        if j % 1000 == 0:\n",
    "            print('j='+str(j))\n",
    "            print(vector_sum.tolist()[0][:10])\n",
    "    return user_vector_dict\n",
    "\n",
    "\n",
    "_user_vector_dict = user_vector_dict(_news_vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "training...\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "[array([[0.45325328, 0.54007946, 0.59499633, 0.60171832, 0.60352323,\n",
      "        0.61098639, 0.61660176, 0.61660176, 0.61921042, 0.61989905,\n",
      "        0.62249817, 0.63575839, 0.63614938, 0.63792183, 0.63904911,\n",
      "        0.64105731, 0.64220264, 0.64352969, 0.64397362, 0.64495954,\n",
      "        0.64577929, 0.64634141, 0.64835796, 0.64962686, 0.64971029,\n",
      "        0.65040481, 0.65073285, 0.65129872, 0.65129872, 0.65236851]]), array([[1632, 2881, 2884, 3050, 1466,  406, 2900, 2062,    5, 2496, 2709,\n",
      "        3198, 2863, 3286,    4,    3,  357, 1167, 1106,  409, 1529, 2492,\n",
      "        1431, 3028, 2999, 1427, 3292, 1292, 2535, 1373]], dtype=int64), array([[0.17796406, 0.48240841, 0.48691549, 0.49153958, 0.49684406,\n",
      "        0.49684406, 0.49701526, 0.49705475, 0.49792756, 0.4990649 ,\n",
      "        0.49958164, 0.50177114, 0.50201981, 0.50226131, 0.5027183 ,\n",
      "        0.50305854, 0.50413008, 0.50418205, 0.50487396, 0.50503168,\n",
      "        0.50565818, 0.50763239, 0.50787672, 0.50860142, 0.50860142,\n",
      "        0.5086558 , 0.50871189, 0.50907552, 0.50915986, 0.50916802]]), array([[1632,   30,    6, 1503,  718, 1495, 2022, 2659, 1529, 1749,  840,\n",
      "        2111,  633, 2492, 1573, 3049, 1465, 1313, 2210, 1720,  651, 3076,\n",
      "        2069, 2062, 2900, 2999, 2652, 1859, 1584, 1294]], dtype=int64), array([[0.30198844, 0.42468827, 0.50467643, 0.51511075, 0.53289277,\n",
      "        0.53628476, 0.53977257, 0.53977257, 0.54593027, 0.54756184,\n",
      "        0.55073314, 0.55187497, 0.55276473, 0.55290094, 0.55416152,\n",
      "        0.55440898, 0.55583209, 0.55585937, 0.55646251, 0.55693199,\n",
      "        0.55709097, 0.55819526, 0.55857515, 0.55960139, 0.55968514,\n",
      "        0.55975535, 0.55978319, 0.55988606, 0.56003436, 0.56073812]]), array([[1632, 2111, 2022,   64,  406,  698, 2062, 2900, 1749, 1584, 3286,\n",
      "        2857, 1573, 1167, 2568, 1574, 2069,  393, 2782, 1168, 2210, 3075,\n",
      "        1060, 2652, 1427, 2491, 2999, 1720, 1414, 1569]], dtype=int64), array([[0.51248434, 0.51825544, 0.54054172, 0.54708411, 0.6501742 ,\n",
      "        0.69227864, 0.69227864, 0.69242468, 0.69321209, 0.69579248,\n",
      "        0.69630097, 0.6968148 , 0.69805894, 0.70166579, 0.70619894,\n",
      "        0.70846016, 0.71014662, 0.71283176, 0.71284892, 0.71293727,\n",
      "        0.7129616 , 0.7135549 , 0.71397416, 0.71411625, 0.71458035,\n",
      "        0.71477474, 0.71526869, 0.71535642, 0.71567766, 0.71588595]]), array([[  58,  103,   30, 1632,  721,  989,  102,  172,  633,  196,  187,\n",
      "         651, 1212, 1749, 1294, 1476, 3264, 1573, 1427, 2111, 2782, 2857,\n",
      "         525, 3150, 2069, 1529, 2022,  968,  547, 1167]], dtype=int64), array([[0.27993865, 0.53150964, 0.54064452, 0.54064452, 0.545136  ,\n",
      "        0.54687247, 0.54915697, 0.5493975 , 0.54942405, 0.55184151,\n",
      "        0.55222486, 0.55256201, 0.55288837, 0.55375045, 0.55517161,\n",
      "        0.55534818, 0.55607543, 0.5562405 , 0.55693776, 0.55714826,\n",
      "        0.55770097, 0.55770097, 0.55822436, 0.55846499, 0.55847172,\n",
      "        0.55869085, 0.55898474, 0.55940502, 0.55941708, 0.55986568]]), array([[1632,  952, 2900, 2062,  406, 2111, 3049, 3286, 1167, 1466,  819,\n",
      "        2492,   30, 3198, 1503, 1529, 2210, 1584,  698, 2022, 1292, 2535,\n",
      "        1106, 1278, 2069, 3292, 2659,  187, 1294, 2073]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "def k_n_n(news_dict, user_dict, k):\n",
    "    news_keys = []\n",
    "    news = []\n",
    "    i = 0\n",
    "    for news_key in news_dict:\n",
    "        news_keys.append(news_key)\n",
    "        news.append(news_dict[news_key])\n",
    "        i += 1\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "    \n",
    "    print(\"training...\")\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    neigh.fit(news)\n",
    "    \n",
    "    user_keys = []\n",
    "    nbrs = []\n",
    "    i = 0\n",
    "    for user_key in user_dict:\n",
    "        users = []\n",
    "        user_keys.append(user_key)\n",
    "        users.append(user_dict[user_key])\n",
    "        nbrs += neigh.kneighbors(users)\n",
    "        i += 1\n",
    "        if i % 50 == 0:\n",
    "            print(i)\n",
    "    \n",
    "#     n = neigh.kneighbors(users)\n",
    "    print(nbrs[:10])\n",
    "    return nbrs\n",
    "\n",
    "k = 30\n",
    "n = k_n_n(_news_vector_dict, _user_vector_dict, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 23, 24, 24, 24, 24, 25, 26, 26, 26]\n"
     ]
    }
   ],
   "source": [
    "news_keys = []\n",
    "i = 0\n",
    "for news_key in _news_vector_dict:\n",
    "    news_keys.append(news_key)\n",
    "\n",
    "    \n",
    "file = codecs.open('./data/_user_data_training_clean.json', 'r', 'utf-8')\n",
    "user_news_dict = json.load(file)\n",
    "\n",
    "result = {}\n",
    "i = 0\n",
    "lens = []\n",
    "for user_key in user_news_dict:\n",
    "    indices = n[2*i+1][0].tolist()\n",
    "    user_news_keys = []\n",
    "    for index in indices:\n",
    "        user_news_key = news_keys[index]\n",
    "        if user_news_key not in user_news_dict[user_key]:\n",
    "            user_news_keys.append(user_news_key)\n",
    "    result.setdefault(user_key, user_news_keys)\n",
    "#     if i < 100:\n",
    "#         print(len(result[user_key]))\n",
    "#         print(result[user_key])\n",
    "#         print(user_news_dict[user_key])\n",
    "    i += 1\n",
    "    lens.append(len(result[user_key]))\n",
    "lens.sort()\n",
    "print(lens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[array([[0.45325328, 0.54007946, 0.59499633, 0.60171832, 0.60352323,\n",
      "        0.61098639, 0.61660176, 0.61660176, 0.61921042, 0.61989905,\n",
      "        0.62249817, 0.63575839, 0.63614938, 0.63792183, 0.63904911,\n",
      "        0.64105731, 0.64220264, 0.64352969, 0.64397362, 0.64495954,\n",
      "        0.64577929, 0.64634141, 0.64835796, 0.64962686, 0.64971029,\n",
      "        0.65040481, 0.65073285, 0.65129872, 0.65129872, 0.65236851]]), array([[1632, 2881, 2884, 3050, 1466,  406, 2900, 2062,    5, 2496, 2709,\n",
      "        3198, 2863, 3286,    4,    3,  357, 1167, 1106,  409, 1529, 2492,\n",
      "        1431, 3028, 2999, 1427, 3292, 1292, 2535, 1373]], dtype=int64), array([[0.17796406, 0.48240841, 0.48691549, 0.49153958, 0.49684406,\n",
      "        0.49684406, 0.49701526, 0.49705475, 0.49792756, 0.4990649 ,\n",
      "        0.49958164, 0.50177114, 0.50201981, 0.50226131, 0.5027183 ,\n",
      "        0.50305854, 0.50413008, 0.50418205, 0.50487396, 0.50503168,\n",
      "        0.50565818, 0.50763239, 0.50787672, 0.50860142, 0.50860142,\n",
      "        0.5086558 , 0.50871189, 0.50907552, 0.50915986, 0.50916802]]), array([[1632,   30,    6, 1503,  718, 1495, 2022, 2659, 1529, 1749,  840,\n",
      "        2111,  633, 2492, 1573, 3049, 1465, 1313, 2210, 1720,  651, 3076,\n",
      "        2069, 2062, 2900, 2999, 2652, 1859, 1584, 1294]], dtype=int64), array([[0.30198844, 0.42468827, 0.50467643, 0.51511075, 0.53289277,\n",
      "        0.53628476, 0.53977257, 0.53977257, 0.54593027, 0.54756184,\n",
      "        0.55073314, 0.55187497, 0.55276473, 0.55290094, 0.55416152,\n",
      "        0.55440898, 0.55583209, 0.55585937, 0.55646251, 0.55693199,\n",
      "        0.55709097, 0.55819526, 0.55857515, 0.55960139, 0.55968514,\n",
      "        0.55975535, 0.55978319, 0.55988606, 0.56003436, 0.56073812]]), array([[1632, 2111, 2022,   64,  406,  698, 2062, 2900, 1749, 1584, 3286,\n",
      "        2857, 1573, 1167, 2568, 1574, 2069,  393, 2782, 1168, 2210, 3075,\n",
      "        1060, 2652, 1427, 2491, 2999, 1720, 1414, 1569]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "print(1)\n",
    "print(n[:6])\n",
    "file_output = codecs.open('./data/tfidf_result.json', 'w', 'utf-8')\n",
    "json.dump(result, file_output)\n",
    "file_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# k = 10\n",
    "# n = k_n_n(news_vector_dict, user_vector_dict, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
